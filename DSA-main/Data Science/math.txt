Probability
    0-1 A Event P(A): Probability 
    p(A) = Preferred or Favourable/all or Sample Space
    P(A and B) = P(A).P(B) independent
    Expected Value: E(A) = p(a)*n
    Numerical Outcome = E(X) = P(A).A+P(B).B+P(C).C
Probability Frequency Distribution
Events and Complements
    A+AC=Sample Space A'
    p(A)+P(B)+P(C) = 1
    A' = B+C 
    p(A') = 1-P(A)
Combinatorics
    Permutations (Arrange set of objects/all objects)
        P(n) = n*(n-1)*....1 = n!
        p(3)=6
    Factorial
        n! = n*(n-1)!
    Variations (Arrange set of objects/not all objects)
        V(n,p) = n^p n->total no of element, p->number of position
        V(n,p) = n!/(n-p)!
        V(10,3) = 720
    Combinations (Select few objects)
        C(10,3) = 120
        C(n,p) = n!/p!(n-p)!
        C=V/P
        C(n,p) = C(n,n-p) i.e. p>n/2>n-p 
    Variety Combinations    
        a*b*c
Bayesian Inference
    Sets
        Empty Set or Null Set-> No Value 
        x belongs A or x in A or A conatins x
        For all x in A: x is even
        A is subset B 
    Properties
        Mutually Exclusive Sets: Never Touch. All complements are mutually exclusive.
            A intersect B = 0, A union B = A + B
        Intersect A union B  = A + B - A intersect B(Additive Law)
        Completely Overlap A intersect B = B, A union B = A 
        Dependent and Independent Sets:
            P(A|B) = P(A intersect B)/P(B) ->Conditional Probability 
            P(A|B) not = P(B|A)
            P(A|B)*P(B) = P(A intersect B)(Multiplicative Law)
    Baye's Law:
        P(A|B) = P(B|A)*P(A)/P(B)
        Use:
            Medical Research
            Business: Finding Candidate
        Independent Event:
Distributions:
    Y-Actual Outcome of event
    y->One possible Outcome
    P(Y=y)-->Probability function
    Finite number of outcome, Infinite number
    Two characteristics:
        Mean: Its average value -> mu , sample_mean-> x_
        Variance: How spread data -> sigma^2, sample variance-> s^2; measured in ^2 units.
        Standard Deviation-> (s^2)^1/2 or s. +ve only 
        sigma^2  = E(Y-mu)^2 = E(Y^2)-E(mu)^2
    More congested middle of distribution more data fall b/w that interval.
    Population Data: All the data 
    Sample Data: Part of it
    Discrete Distribution:
        We can add probablity of value in range. 
        P(Y<=y)=P(Y<(y+1))
        Rolling a Die or Picking a card->Equiprobable or Uniform Distribution 
            Uniform probablity: Both mean and variance are interpretable
        When one trial and only two outcome-> Bernouli Distrbution
            X~Bern(p)
            s^2=p*(1-p)
        Binomial Distribution: Sequence of identical Bernouli events.
            X~B(n,p) n=number of events
            p(y) = C(n,y)* p^y *(1-p)^(n-y)
            s^2=E(y^2)-E(y)^2=n.p.(1-p)
        Poisson Distribution: Frequency with which an event occur.
            Y~Po(lambda)
            P(Y)=lambda^y.e^-y/y! e=euler's number or(2.72)
            E(y)=lambda= Both mean and s^2 called as elegant statistics.
    Continuous Distribution:
        Not represent by table. represent by graph.
        PDF: Probability distribution function. f(y)>=0 <--integral--derivative-->CDF
        Probability of any individual is 0.
        CDF: Cumulative Distrbution Function.F(y)=P(Y<=y)
        Var(y)=E(y^2)-E(y)^2
        Discrete CDFs
        Speed and Time: Probability distribution could be curve.
        Normal Distribution:
            Polar Bears->350 500 700. Extreme are outliers.Graph is bell shaped.
            X~N(u,sig^2)
            68(u-sig)-(u+sig), 95(u-2*sig)-(u+2*sig), 99.7(u-3*sig)-(u+3*sig) Law lie in mean - amount of Standard deviation
            Transformation: Way to alter every element of transformation to new trasnformation like -+%*
                If multiply graph shrink, divide graph expand, add left shift, subtract right shift.
            Standardizing: Special type transformation Mean E(X)=0, SD Var(X)=1 Z=Y-u/sig 
        Student-Ts Distrbution:
            Accomodate extreme value better.Bell shaped and symmetric curve.
            k degree of freedom Y~t(3) It has flatten tail
            If K>2 E(Y)=u Var(Y)=S^2*K/k-2
        Chi-Squared:
            Asymetric. Only consist of non-symmetric value.
            Does't show real life. Used in Hypothesis testing. Goodness of fit. Few events in real life.
            Y=Chi^2(k) Graph highly skewed right. E(X)=k, Var(X)=2*k
        Exponential Distribution:
            Event rapidly changing on
            Exp(lam) Exp(1/2) Youtube views. lam->rate param
        Logistic Distribution:
            Forecast Analysis. Never reach true certainity. How much game necessary to predict victory.
            Log(u,S) S-Scale param
            E(Y)=u, Var(Y)=S^2pi^2/3

Matrix
    Collection of number ordered in rows and columns.
    A = [5 12 6-------->Element 
    -3 0 14]
    2 rows * 3columns
    Addition
    Subtraction 
    Multiplication
Scalars(No Dimension)
    Number we know from algebra are referred
    Point
Vectors(One Dimnesion) like Line
    Simplest linear algebaric object
    Row [3 4]
    Column [3
            4]
Matrix m*n 
    Collections of vectors
3-D Vector plotter to play with matrix.
Tensor:
    Collections of matrices
    k*m*n
Addition and Subtraction:
    Two matrices should have same dimension.
    m1+m2
    m1+1
Transpose:
    Value not changing only position. 1*3 become 3*1. Transpose twice give initial matrix.
    Vector and Scalar transpose give same result.
    [1
    2
    3], [1 2 3]
    (xT)T=x
    A=np.array([[5,12,6], [-3,0,14]])
    A.T
Multiplication:
    Sclar Multiply 
    Dot Product(inner or scalar): Two vectors gives scalar
        np.dot(x, y)
        Only multiply m*n with n*k gives m*k.
    Tensor Product(outer)
    [2    [1
    8       -7
    -4]      3]=2*1+8*-7+-4*3=-66

Linear Algebra Useful:
    Application in Data Science
        Vectorized code 
            inputs . weights(coefficients) = outputs
            Using algebra to compute many value simultaneously.
            much faster. Library like Numpy
        Image Recognition
            Deep Learning 
            CNNS Convolutional neural networks
            MNIST CIFAR10 CIFAR100 
            Grey scale 0-255 intensity
            How to represent color RGB scale 3*400*400 tensor
        Dimensionality Reduction
            Eigen Values and Eigen Vectors
            Combining similar features in one category

type(10) #int 
int(5.0)
float(5)
str(500)
max(10,20,30)
min(10,20,30)
abs(-10)
sum([1,2,3,4])
round(3.555,2)
round(3.2)
pow(2,10)
len('Mathematics')
arr.index(ele)
arr.sort(reverse=True)
math.sqrt(16)


            


