Probability
    0-1 A Event P(A): Probability 
    p(A) = Preferred or Favourable/all or Sample Space
    P(A and B) = P(A).P(B) independent
    Expected Value: E(A) = p(a)*n
    Numerical Outcome = E(X) = P(A).A+P(B).B+P(C).C
Probability Frequency Distribution
Events and Complements
    A+AC=Sample Space A'
    p(A)+P(B)+P(C) = 1
    A' = B+C 
    p(A') = 1-P(A)
Combinatorics
    Permutations (Arrange set of objects/all objects)
        P(n) = n*(n-1)*....1 = n!
        p(3)=6
    Factorial
        n! = n*(n-1)!
    Variations (Arrange set of objects/not all objects)
        V(n,p) = n^p n->total no of element, p->number of position
        V(n,p) = n!/(n-p)!
        V(10,3) = 720
    Combinations (Select few objects)
        C(10,3) = 120
        C(n,p) = n!/p!(n-p)!
        C=V/P
        C(n,p) = C(n,n-p) i.e. p>n/2>n-p 
    Variety Combinations    
        a*b*c
Bayesian Inference
    Sets
        Empty Set or Null Set-> No Value 
        x belongs A or x in A or A conatins x
        For all x in A: x is even
        A is subset B 
    Properties
        Mutually Exclusive Sets: Never Touch. All complements are mutually exclusive.
            A intersect B = 0, A union B = A + B
        Intersect A union B  = A + B - A intersect B(Additive Law)
        Completely Overlap A intersect B = B, A union B = A 
        Dependent and Independent Sets:
            P(A|B) = P(A intersect B)/P(B) ->Conditional Probability 
            P(A|B) not = P(B|A)
            P(A|B)*P(B) = P(A intersect B)(Multiplicative Law)
    Baye's Law:
        P(A|B) = P(B|A)*P(A)/P(B)
        Use:
            Medical Research
            Business: Finding Candidate
        Independent Event:
Distributions:
    Y-Actual Outcome of event
    y->One possible Outcome
    P(Y=y)-->Probability function
    Finite number of outcome, Infinite number
    Two characteristics:
        Mean: Its average value -> mu , sample_mean-> x_
        Variance: How spread data -> sigma^2, sample variance-> s^2; measured in ^2 units.
        Standard Deviation-> (s^2)^1/2 or s. +ve only 
        sigma^2  = E(Y-mu)^2 = E(Y^2)-E(mu)^2
    More congested middle of distribution more data fall b/w that interval.
    Population Data: All the data 
    Sample Data: Part of it
    Discrete Distribution:
        We can add probablity of value in range. 
        P(Y<=y)=P(Y<(y+1))
        Rolling a Die or Picking a card->Equiprobable or Uniform Distribution 
            Uniform probablity: Both mean and variance are interpretable
        When one trial and only two outcome-> Bernouli Distrbution
            X~Bern(p)
            s^2=p*(1-p)
        Binomial Distribution: Sequence of identical Bernouli events.
            X~B(n,p) n=number of events
            p(y) = C(n,y)* p^y *(1-p)^(n-y)
            s^2=E(y^2)-E(y)^2=n.p.(1-p)
        Poisson Distribution: Frequency with which an event occur.
            Y~Po(lambda)
            P(Y)=lambda^y.e^-y/y! e=euler's number or(2.72)
            E(y)=lambda= Both mean and s^2 called as elegant statistics.

    Continuous Distribution:
        Speed and Time: Probability distribution could be curve.
        Normal Distribution:
            Polar Bears->350 500 700. Extreme are outliers.
        Student-Ts Distrbution:
            Accomodate extreme value better. 
        Chi-Squared:
            Asymetric. Only consist of non-symmetric value.
            Does't show real life. Used in Hypothesis testing. Goodness of fit.
        Exponential Distribution:
            Event rapidly changing on
        Logistic Distribution:
            Forecast Analysis. Never reach true certainity. How much game necessary to predict victory.

            


